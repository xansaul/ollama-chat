version: "3"

name: chat-bot

services:

  frontend:
    build:
      context: ../../
      dockerfile: docker/production/Dockerfile
    image: ollama-chat
    ports:
      - "3000:3000"
    
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    restart: always
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['all']
              capabilities: [gpu]